# Prompt Review & Feedback Workflow

## Purpose
To ensure prompt quality, relevance, and compliance across LRMC use cases.

## Roles
- **Prompt Engineer**: Designs and updates prompts
- **Domain SME**: Validates legal/regulatory accuracy
- **Governance Lead**: Oversees risk, bias, and audit readiness

## Review Stages
1. **Draft Submission**
   - Prompt engineer submits new or updated prompt
2. **SME Review**
   - Domain expert checks for accuracy and relevance
3. **Governance Review**
   - Bias, hallucination, and compliance check
4. **Approval**
   - Prompt tagged as `Approved` and published
5. **Feedback Loop**
   - Users submit feedback via GitHub Issues or form
   - Prompt engineer logs feedback in `PromptFeedback` table

## Review Cadence
- Monthly review of active prompts
- Quarterly audit of deprecated prompts

## Feedback Categories
- Accuracy issues
- Output formatting errors
- Misalignment with use case
- Hallucination or bias risks

## Documentation
All reviews must be logged with:
- Reviewer name
- Date
- Summary of findings
- Action taken
